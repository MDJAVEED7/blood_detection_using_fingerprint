{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":29347,"status":"ok","timestamp":1735367386457,"user":{"displayName":"Anjali Patil","userId":"07749654580873159626"},"user_tz":-330},"id":"sGUfNzOR3xJc","outputId":"1aae1a29-1e3b-43ac-ddc1-2ce427102909"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"vazIdI8N38Z-"},"outputs":[],"source":["import os\n","import numpy as np\n","import tensorflow as tf\n","from tensorflow.keras.preprocessing.image import ImageDataGenerator\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n","from tensorflow.keras.optimizers import Adam\n","from sklearn.model_selection import train_test_split\n","import matplotlib.pyplot as plt\n","from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":10486,"status":"ok","timestamp":1735367409265,"user":{"displayName":"Anjali Patil","userId":"07749654580873159626"},"user_tz":-330},"id":"OUim1HOV38cv","outputId":"dfa4cbbc-7b52-4670-cf14-7afd3a08e884"},"outputs":[{"output_type":"stream","name":"stdout","text":["Found 5600 images belonging to 8 classes.\n","Found 1200 images belonging to 8 classes.\n"]}],"source":["train_dir = '/content/drive/MyDrive/split_minip/train'\n","val_dir = '/content/drive/MyDrive/split_minip/val'\n","test_dir = '/content/drive/MyDrive/split_minip/test'\n","\n","train_gen = ImageDataGenerator(rescale=1./255)\n","val_gen = ImageDataGenerator(rescale=1./255)\n","test_gen = ImageDataGenerator(rescale=1./255)\n","\n","train_data = train_gen.flow_from_directory(train_dir, target_size=(224, 224), batch_size=32, class_mode='categorical')\n","val_data = val_gen.flow_from_directory(val_dir, target_size=(224, 224), batch_size=32, class_mode='categorical')\n","test_data = test_gen.flow_from_directory(test_dir, target_size=(224, 224), batch_size=32, class_mode='categorical')"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":7312,"status":"ok","timestamp":1735072187082,"user":{"displayName":"Anjali Patil","userId":"07749654580873159626"},"user_tz":-330},"id":"VxPcShXr38fl","outputId":"7e9c973a-4310-4dbf-a975-6fe08a110d75"},"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n","\u001b[1m58889256/58889256\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 0us/step\n"]}],"source":["# Base model: VGG16 (without top/fully connected layers)\n","base_model = tf.keras.applications.VGG16(weights=\"imagenet\", include_top=False, input_shape=(224, 224, 3))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Wk5X-yaR38iC"},"outputs":[],"source":["for layer in base_model.layers:\n","    layer.trainable = False\n","x = base_model.output\n","x = Flatten()(x)\n","x = Dense(512, activation='relu')(x)\n","x = Dropout(0.5)(x)\n","output = Dense(8, activation='softmax')(x)\n","\n","model = tf.keras.Model(inputs=base_model.input, outputs=output)"]},{"cell_type":"code","source":["model.compile(optimizer=Adam(learning_rate=0.0001), loss='categorical_crossentropy', metrics=['accuracy'])"],"metadata":{"id":"ZQ77cijWSSMN"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n","checkpoint_path = '/content/drive/MyDrive/vggbest_model.keras'\n","final_model_path = '/content/drive/MyDrive/vggfinal_model.keras'\n","early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n","\n","model_checkpoint = ModelCheckpoint(\n","    checkpoint_path,\n","    monitor='val_loss',\n","    save_best_only=True,\n",")\n","\n","history = model.fit(\n","    train_data,\n","    validation_data=val_data,\n","    epochs=30,\n","    callbacks=[early_stopping, model_checkpoint]\n",")\n","model.save(final_model_path)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"EZGSVh7vWjZZ","executionInfo":{"status":"ok","timestamp":1735077611320,"user_tz":-330,"elapsed":5344075,"user":{"displayName":"Anjali Patil","userId":"07749654580873159626"}},"outputId":"023ac0cc-6979-465e-9055-edbe4a50ef10"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/30\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:122: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n","  self._warn_if_super_not_called()\n"]},{"output_type":"stream","name":"stdout","text":["\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4759s\u001b[0m 26s/step - accuracy: 0.5079 - loss: 1.3424 - val_accuracy: 0.8077 - val_loss: 0.5308\n","Epoch 2/30\n","\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 194ms/step - accuracy: 0.7804 - loss: 0.5804 - val_accuracy: 0.8718 - val_loss: 0.4030\n","Epoch 3/30\n","\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 188ms/step - accuracy: 0.8314 - loss: 0.4609 - val_accuracy: 0.8676 - val_loss: 0.3817\n","Epoch 4/30\n","\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 216ms/step - accuracy: 0.8455 - loss: 0.4072 - val_accuracy: 0.8776 - val_loss: 0.3495\n","Epoch 5/30\n","\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 191ms/step - accuracy: 0.8670 - loss: 0.3521 - val_accuracy: 0.8709 - val_loss: 0.3326\n","Epoch 6/30\n","\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 181ms/step - accuracy: 0.8921 - loss: 0.2892 - val_accuracy: 0.8743 - val_loss: 0.3412\n","Epoch 7/30\n","\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 185ms/step - accuracy: 0.8996 - loss: 0.2766 - val_accuracy: 0.8876 - val_loss: 0.2949\n","Epoch 8/30\n","\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 192ms/step - accuracy: 0.9154 - loss: 0.2387 - val_accuracy: 0.8934 - val_loss: 0.2915\n","Epoch 9/30\n","\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 186ms/step - accuracy: 0.9215 - loss: 0.2139 - val_accuracy: 0.8809 - val_loss: 0.3123\n","Epoch 10/30\n","\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 219ms/step - accuracy: 0.9338 - loss: 0.1930 - val_accuracy: 0.8951 - val_loss: 0.2857\n","Epoch 11/30\n","\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 181ms/step - accuracy: 0.9380 - loss: 0.1777 - val_accuracy: 0.8851 - val_loss: 0.2908\n","Epoch 12/30\n","\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 179ms/step - accuracy: 0.9424 - loss: 0.1662 - val_accuracy: 0.8818 - val_loss: 0.3258\n","Epoch 13/30\n","\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 178ms/step - accuracy: 0.9486 - loss: 0.1462 - val_accuracy: 0.8834 - val_loss: 0.2879\n","Epoch 14/30\n","\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 180ms/step - accuracy: 0.9503 - loss: 0.1409 - val_accuracy: 0.8884 - val_loss: 0.2893\n","Epoch 15/30\n","\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 178ms/step - accuracy: 0.9632 - loss: 0.1198 - val_accuracy: 0.8893 - val_loss: 0.2987\n"]}]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":10999,"status":"ok","timestamp":1735077704531,"user":{"displayName":"Anjali Patil","userId":"07749654580873159626"},"user_tz":-330},"id":"xdT6kf0K38nR","outputId":"dcdce595-c6b7-4835-f432-896ea3c004de"},"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 131ms/step - accuracy: 0.9079 - loss: 0.2610\n","Validation Loss: 0.2857494056224823\n","Validation Accuracy: 0.8950874209403992\n"]}],"source":["val_loss, val_accuracy = model.evaluate(val_data) #model evalution on val data\n","\n","print(f'Validation Loss: {val_loss}')\n","print(f'Validation Accuracy: {val_accuracy}')"]},{"cell_type":"code","source":["from tensorflow.keras.preprocessing.image import ImageDataGenerator\n","import warnings\n","warnings.filterwarnings(\"ignore\", category=UserWarning, module=\"keras.src.trainers.data_adapters.py_dataset_adapter\")\n","\n","test_dir = '/content/drive/MyDrive/split_minip/test'\n","test_gen = ImageDataGenerator(rescale=1./255)\n","test_data = test_gen.flow_from_directory(test_dir,target_size=(224, 224),batch_size=32,class_mode='categorical')\n","\n","test_loss, test_accuracy = model.evaluate(test_data)\n","print(f\"Test Loss: {test_loss:.4f}\")\n","print(f\"Test Accuracy: {test_accuracy * 100:.4f}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"LSo87Rky97Sx","executionInfo":{"status":"ok","timestamp":1735368399358,"user_tz":-330,"elapsed":349166,"user":{"displayName":"Anjali Patil","userId":"07749654580873159626"}},"outputId":"a11d26e6-9cde-4dc4-e606-3973080db6ac"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Found 1160 images belonging to 8 classes.\n","\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m326s\u001b[0m 9s/step - accuracy: 0.8905 - loss: 0.2944\n","Test Loss: 0.2889\n","Test Accuracy: 88.7931\n"]}]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[],"authorship_tag":"ABX9TyNeYAz4rGhZOQzO9yNq5Jb2"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}